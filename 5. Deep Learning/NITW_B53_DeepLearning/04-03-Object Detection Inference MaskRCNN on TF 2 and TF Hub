{"cells":[{"cell_type":"markdown","metadata":{"id":"98rds-2OU-Rd"},"source":["##### Copyright 2020 The TensorFlow Hub Authors.\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"1c95xMGcU5_Z"},"outputs":[],"source":["#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# =============================================================================="]},{"cell_type":"markdown","metadata":{"id":"V1UUX8SUUiMO"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tf2_object_detection\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","  <td>\n","    <a href=\"https://tfhub.dev/tensorflow/collections/object_detection/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub models</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"rOvvWAVTkMR7"},"source":["# TensorFlow Hub Object Detection Colab\n","\n","Welcome to the TensorFlow Hub Object Detection Colab! This notebook will take you through the steps of running an \"out-of-the-box\" object detection model on images."]},{"cell_type":"markdown","metadata":{"id":"IRImnk_7WOq1"},"source":["### More models\n","[This](https://tfhub.dev/tensorflow/collections/object_detection/1) collection contains TF2 object detection models that have been trained on the COCO 2017 dataset. [Here](https://tfhub.dev/s?module-type=image-object-detection) you can find all object detection models that are currently hosted on [tfhub.dev](https://tfhub.dev/)."]},{"cell_type":"markdown","metadata":{"id":"vPs64QA1Zdov"},"source":["## Imports and Setup\n","\n","Let's start with the base imports."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xk4FU-jx9kc3"},"outputs":[],"source":["# This Colab requires TF 2.5.\n","!pip install -U \"tensorflow>=2.5\""]},{"cell_type":"code","execution_count":1,"metadata":{"id":"yn5_uV1HLvaz","executionInfo":{"status":"ok","timestamp":1682745098948,"user_tz":-330,"elapsed":4089,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}}},"outputs":[],"source":["import os\n","import pathlib\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from six.moves.urllib.request import urlopen\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","tf.get_logger().setLevel('ERROR')"]},{"cell_type":"markdown","metadata":{"id":"IogyryF2lFBL"},"source":["## Utilities\n","\n","Run the following cell to create some utils that will be needed later:\n","\n","- Helper method to load an image\n","- Map of Model Name to TF Hub handle\n","- List of tuples with Human Keypoints for the COCO 2017 dataset. This is needed for models with keypoints."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-y9R0Xllefec","executionInfo":{"status":"ok","timestamp":1682745137332,"user_tz":-330,"elapsed":599,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}}},"outputs":[],"source":["# @title Run this!!\n","\n","def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: the file path to the image\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  image = None\n","  if(path.startswith('http')):\n","    response = urlopen(path)\n","    image_data = response.read()\n","    image_data = BytesIO(image_data)\n","    image = Image.open(image_data)\n","  else:\n","    image_data = tf.io.gfile.GFile(path, 'rb').read()\n","    image = Image.open(BytesIO(image_data))\n","\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (1, im_height, im_width, 3)).astype(np.uint8)\n","\n","\n","ALL_MODELS = {\n","'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n","'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n","'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n","'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n","'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n","'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n","'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n","'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n","'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n","'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n","'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n","'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n","'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n","'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n","'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n","'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n","'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n","'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n","'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n","'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n","'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n","'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n","'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n","'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n","'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n","'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n","'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n","'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n","'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n","'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n","'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n","'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n","'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n","'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n","'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n","'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n","'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n","'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n","'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n","}\n","\n","IMAGES_FOR_TEST = {\n","  'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n","  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',\n","  # By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg\n","  'Naxos Taverna' : 'https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg',\n","  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n","  'Beatles' : 'https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg',\n","  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n","  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n","  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\n","  'Birds' : 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg',\n","}\n","\n","COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n"," (0, 2),\n"," (1, 3),\n"," (2, 4),\n"," (0, 5),\n"," (0, 6),\n"," (5, 7),\n"," (7, 9),\n"," (6, 8),\n"," (8, 10),\n"," (5, 6),\n"," (5, 11),\n"," (6, 12),\n"," (11, 12),\n"," (11, 13),\n"," (13, 15),\n"," (12, 14),\n"," (14, 16)]"]},{"cell_type":"markdown","metadata":{"id":"14bNk1gzh0TN"},"source":["## Visualization tools\n","\n","To visualize the images with the proper detected boxes, keypoints and segmentation, we will use the TensorFlow Object Detection API. To install it we will clone the repo."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5180,"status":"ok","timestamp":1682745155431,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"},"user_tz":-330},"id":"oi28cqGGFWnY","outputId":"18d8d208-335e-47d4-8d91-4db3f3a156fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 3736, done.\u001b[K\n","remote: Counting objects: 100% (3736/3736), done.\u001b[K\n","remote: Compressing objects: 100% (2870/2870), done.\u001b[K\n","remote: Total 3736 (delta 1066), reused 1868 (delta 816), pack-reused 0\u001b[K\n","Receiving objects: 100% (3736/3736), 48.75 MiB | 21.96 MiB/s, done.\n","Resolving deltas: 100% (1066/1066), done.\n"]}],"source":["# Clone the tensorflow models repository\n","!git clone --depth 1 https://github.com/tensorflow/models"]},{"cell_type":"markdown","metadata":{"id":"yX3pb_pXDjYA"},"source":["Intalling the Object Detection API"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"NwdsBdGhFanc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682745234071,"user_tz":-330,"elapsed":61735,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}},"outputId":"17d9b1e8-a68e-4064-d950-9836487e85a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","protobuf-compiler is already the newest version (3.6.1.3-2ubuntu5.2).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/models/research\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting apache-beam\n","  Downloading apache_beam-2.46.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.2 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.2/14.2 MB 90.5 MB/s eta 0:00:00\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (8.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.29.34)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (0.6.0.post1)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.6)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.10.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.12.0-py2.py3-none-any.whl (2.6 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 96.5 MB/s eta 0:00:00\n","Collecting tensorflow_io\n","  Downloading tensorflow_io-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 28.0/28.0 MB 58.2 MB/s eta 0:00:00\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.12.0)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 10.2 MB/s eta 0:00:00\n","Collecting sacrebleu<=2.2.0\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 16.2 MB/s eta 0:00:00\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.22.4)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.10.31)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.4-py2.py3-none-any.whl (240 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.6/240.6 kB 26.6 MB/s eta 0:00:00\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.13.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n","Requirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.12.0)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 591.0/591.0 kB 46.6 MB/s eta 0:00:00\n","Collecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 175.1/175.1 kB 14.3 MB/s eta 0:00:00\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.3)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 80.7 MB/s eta 0:00:00\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.13)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.72)\n","Collecting immutabledict\n","  Downloading immutabledict-2.2.4-py3-none-any.whl (4.1 kB)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.7 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting tensorflow-text~=2.12.0\n","  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 113.1 MB/s eta 0:00:00\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n","Collecting fasteners<1.0,>=0.3\n","  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n","Collecting zstandard<1,>=0.18.0\n","  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 64.1 MB/s eta 0:00:00\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.27.1)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Collecting crcmod<2.0,>=1.7\n","  Downloading crcmod-1.7.tar.gz (89 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 11.6 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting orjson<4.0\n","  Downloading orjson-3.8.11-cp310-cp310-manylinux_2_28_x86_64.whl (135 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 15.1 MB/s eta 0:00:00\n","Requirement already satisfied: httplib2<0.22.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.21.0)\n","Requirement already satisfied: pyarrow<10.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n","Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 74.2 MB/s eta 0:00:00\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 kB 20.8 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 516.2/516.2 kB 44.2 MB/s eta 0:00:00\n","Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.54.0)\n","Collecting objsize<0.7.0,>=0.6.1\n","  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.7.0.72)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (23.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.0.7)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.39.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.32.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n","Collecting docopt\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.26.15)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.65.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.0)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.12.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.12.2)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (23.3.3)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n","Collecting numpy>=1.17\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 93.8 MB/s eta 0:00:00\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n","Collecting typeguard<3.0.0,>=2.7\n","  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.3)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.13.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.40.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.15.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.12.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.59.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.3)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n","Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, pyyaml, seqeval, docopt\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697012 sha256=be586abccd753af4378121b0d93beb6037fa08de98fa3ba67e4583557b9fa7ed\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7ths_3p3/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44008 sha256=5b81f53536e6fdd30390012ef2ff8e0bd27546d500eac5142b053cc0c5b46011\n","  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n","  Building wheel for crcmod (setup.py): started\n","  Building wheel for crcmod (setup.py): finished with status 'done'\n","  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=37108 sha256=db1310223b60437ac8b36690ceceb81b152f5a8165dc78ca654ea5e3da1f84c2\n","  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=cf5489e462a77a2ab421a2e8621681ef21d4a48dad0c0a6d2256ee8d78a024e2\n","  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n","  Building wheel for pyyaml (pyproject.toml): started\n","  Building wheel for pyyaml (pyproject.toml): finished with status 'done'\n","  Created wheel for pyyaml: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=58edb93d2a81e67cd5f04d5983efa0f75c2758417bcba68f30e3c44efcf9cf8d\n","  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n","  Building wheel for seqeval (setup.py): started\n","  Building wheel for seqeval (setup.py): finished with status 'done'\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=2a74746993f947dbb2779c85d4655ceccefb03ae24b4d75713282dc84cb30997\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","  Building wheel for docopt (setup.py): started\n","  Building wheel for docopt (setup.py): finished with status 'done'\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=c8543f2b050eab43e4768c86a8748bf5d5d71e69486d22587c6fedc08b8df53b\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built object-detection avro-python3 crcmod dill pyyaml seqeval docopt\n","Installing collected packages: sentencepiece, docopt, crcmod, zstandard, typeguard, tensorflow_io, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, numpy, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, tensorflow-model-optimization, tensorflow-addons, sacrebleu, hdfs, apache-beam, seqeval, lvis, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","Successfully installed apache-beam-2.46.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.3 fasteners-0.18 hdfs-2.7.0 immutabledict-2.2.4 lvis-0.5.3 numpy-1.23.5 object-detection-0.1 objsize-0.6.1 orjson-3.8.11 portalocker-2.7.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.98 seqeval-1.2.2 tensorflow-addons-0.20.0 tensorflow-model-optimization-0.7.4 tensorflow-text-2.12.1 tensorflow_io-0.32.0 tf-models-official-2.12.0 typeguard-2.13.3 zstandard-0.21.0\n"]},{"output_type":"stream","name":"stderr","text":["\n","WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n","\n"]}],"source":["%%bash\n","sudo apt install -y protobuf-compiler\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n"]},{"cell_type":"markdown","metadata":{"id":"3yDNgIx-kV7X"},"source":["Now we can import the dependencies we will need later"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2JCeQU3fkayh","executionInfo":{"status":"ok","timestamp":1682745292893,"user_tz":-330,"elapsed":973,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}},"colab":{"base_uri":"https://localhost:8080/","height":117},"outputId":"be34c7da-2fcb-4349-e601-bbe93ce5d138"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf"]}],"source":["from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import ops as utils_ops\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"NKtD0IeclbL5"},"source":["### Load label map data (for plotting).\n","\n","Label maps correspond index numbers to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine.\n","\n","We are going, for simplicity, to load from the repository that we loaded the Object Detection API code"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5mucYUS6exUJ","executionInfo":{"status":"ok","timestamp":1682745336039,"user_tz":-330,"elapsed":544,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}}},"outputs":[],"source":["PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"]},{"cell_type":"code","source":["category_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m69Qqc-gxQXI","executionInfo":{"status":"ok","timestamp":1682745340497,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}},"outputId":"ba78d3e6-8360-47b8-c0b5-64fe2333eba2"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{1: {'id': 1, 'name': 'person'},\n"," 2: {'id': 2, 'name': 'bicycle'},\n"," 3: {'id': 3, 'name': 'car'},\n"," 4: {'id': 4, 'name': 'motorcycle'},\n"," 5: {'id': 5, 'name': 'airplane'},\n"," 6: {'id': 6, 'name': 'bus'},\n"," 7: {'id': 7, 'name': 'train'},\n"," 8: {'id': 8, 'name': 'truck'},\n"," 9: {'id': 9, 'name': 'boat'},\n"," 10: {'id': 10, 'name': 'traffic light'},\n"," 11: {'id': 11, 'name': 'fire hydrant'},\n"," 13: {'id': 13, 'name': 'stop sign'},\n"," 14: {'id': 14, 'name': 'parking meter'},\n"," 15: {'id': 15, 'name': 'bench'},\n"," 16: {'id': 16, 'name': 'bird'},\n"," 17: {'id': 17, 'name': 'cat'},\n"," 18: {'id': 18, 'name': 'dog'},\n"," 19: {'id': 19, 'name': 'horse'},\n"," 20: {'id': 20, 'name': 'sheep'},\n"," 21: {'id': 21, 'name': 'cow'},\n"," 22: {'id': 22, 'name': 'elephant'},\n"," 23: {'id': 23, 'name': 'bear'},\n"," 24: {'id': 24, 'name': 'zebra'},\n"," 25: {'id': 25, 'name': 'giraffe'},\n"," 27: {'id': 27, 'name': 'backpack'},\n"," 28: {'id': 28, 'name': 'umbrella'},\n"," 31: {'id': 31, 'name': 'handbag'},\n"," 32: {'id': 32, 'name': 'tie'},\n"," 33: {'id': 33, 'name': 'suitcase'},\n"," 34: {'id': 34, 'name': 'frisbee'},\n"," 35: {'id': 35, 'name': 'skis'},\n"," 36: {'id': 36, 'name': 'snowboard'},\n"," 37: {'id': 37, 'name': 'sports ball'},\n"," 38: {'id': 38, 'name': 'kite'},\n"," 39: {'id': 39, 'name': 'baseball bat'},\n"," 40: {'id': 40, 'name': 'baseball glove'},\n"," 41: {'id': 41, 'name': 'skateboard'},\n"," 42: {'id': 42, 'name': 'surfboard'},\n"," 43: {'id': 43, 'name': 'tennis racket'},\n"," 44: {'id': 44, 'name': 'bottle'},\n"," 46: {'id': 46, 'name': 'wine glass'},\n"," 47: {'id': 47, 'name': 'cup'},\n"," 48: {'id': 48, 'name': 'fork'},\n"," 49: {'id': 49, 'name': 'knife'},\n"," 50: {'id': 50, 'name': 'spoon'},\n"," 51: {'id': 51, 'name': 'bowl'},\n"," 52: {'id': 52, 'name': 'banana'},\n"," 53: {'id': 53, 'name': 'apple'},\n"," 54: {'id': 54, 'name': 'sandwich'},\n"," 55: {'id': 55, 'name': 'orange'},\n"," 56: {'id': 56, 'name': 'broccoli'},\n"," 57: {'id': 57, 'name': 'carrot'},\n"," 58: {'id': 58, 'name': 'hot dog'},\n"," 59: {'id': 59, 'name': 'pizza'},\n"," 60: {'id': 60, 'name': 'donut'},\n"," 61: {'id': 61, 'name': 'cake'},\n"," 62: {'id': 62, 'name': 'chair'},\n"," 63: {'id': 63, 'name': 'couch'},\n"," 64: {'id': 64, 'name': 'potted plant'},\n"," 65: {'id': 65, 'name': 'bed'},\n"," 67: {'id': 67, 'name': 'dining table'},\n"," 70: {'id': 70, 'name': 'toilet'},\n"," 72: {'id': 72, 'name': 'tv'},\n"," 73: {'id': 73, 'name': 'laptop'},\n"," 74: {'id': 74, 'name': 'mouse'},\n"," 75: {'id': 75, 'name': 'remote'},\n"," 76: {'id': 76, 'name': 'keyboard'},\n"," 77: {'id': 77, 'name': 'cell phone'},\n"," 78: {'id': 78, 'name': 'microwave'},\n"," 79: {'id': 79, 'name': 'oven'},\n"," 80: {'id': 80, 'name': 'toaster'},\n"," 81: {'id': 81, 'name': 'sink'},\n"," 82: {'id': 82, 'name': 'refrigerator'},\n"," 84: {'id': 84, 'name': 'book'},\n"," 85: {'id': 85, 'name': 'clock'},\n"," 86: {'id': 86, 'name': 'vase'},\n"," 87: {'id': 87, 'name': 'scissors'},\n"," 88: {'id': 88, 'name': 'teddy bear'},\n"," 89: {'id': 89, 'name': 'hair drier'},\n"," 90: {'id': 90, 'name': 'toothbrush'}}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"6917xnUSlp9x"},"source":["## Build a detection model and load pre-trained model weights\n","\n","Here we will choose which Object Detection model we will use.\n","Select the architecture and it will be loaded automatically.\n","If you want to change the model to try other architectures later, just change the next cell and execute following ones.\n","\n","**Tip:** if you want to read more details about the selected model, you can follow the link (model handle) and read additional documentation on TF Hub. After you select a model, we will print the handle to make it easier."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":547,"status":"ok","timestamp":1682745481854,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"},"user_tz":-330},"id":"HtwrSqvakTNn","outputId":"6f5fe91b-74af-4dfd-bb9d-b406ceebdf2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected model:Mask R-CNN Inception ResNet V2 1024x1024\n","Model Handle at TensorFlow Hub: https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1\n"]}],"source":["#@title Model Selection { display-mode: \"form\", run: \"auto\" }\n","model_display_name = 'Mask R-CNN Inception ResNet V2 1024x1024' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']\n","model_handle = ALL_MODELS[model_display_name]\n","\n","print('Selected model:'+ model_display_name)\n","print('Model Handle at TensorFlow Hub: {}'.format(model_handle))"]},{"cell_type":"markdown","metadata":{"id":"muhUt-wWL582"},"source":["## Loading the selected model from TensorFlow Hub\n","\n","Here we just need the model handle that was selected and use the Tensorflow Hub library to load it to memory.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37786,"status":"ok","timestamp":1682745539298,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"},"user_tz":-330},"id":"rBuD07fLlcEO","outputId":"e9dbbd2a-535d-450c-daf2-0d4072d90525"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading model...\n","model loaded!\n"]}],"source":["print('loading model...')\n","hub_model = hub.load(model_handle)\n","print('model loaded!')"]},{"cell_type":"markdown","metadata":{"id":"GIawRDKPPnd4"},"source":["## Loading an image\n","\n","Let's try the model on a simple image. To help with this, we provide a list of test images.\n","\n","Here are some simple things to try out if you are curious:\n","* Try running inference on your own images, just upload them to colab and load the same way it's done in the cell below.\n","* Modify some of the input images and see if detection still works.  Some simple things to try out here include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).\n","\n","**Be careful:** when using images with an alpha channel, the model expect 3 channels images and the alpha will count as a 4th.\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717,"output_embedded_package_id":"1vr0Za2WURP8DA0jj-4mHcH4jYvF0pprc"},"executionInfo":{"elapsed":13444,"status":"ok","timestamp":1682745562740,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"},"user_tz":-330},"id":"hX-AWUQ1wIEr","outputId":"a6a89d73-b3e2-49c7-e379-059e75a4cc79"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#@title Image Selection (don't forget to execute the cell!) { display-mode: \"form\"}\n","selected_image = 'Beach' # @param ['Beach', 'Dogs', 'Naxos Taverna', 'Beatles', 'Phones', 'Birds']\n","flip_image_horizontally = False #@param {type:\"boolean\"}\n","convert_image_to_grayscale = False #@param {type:\"boolean\"}\n","\n","image_path = IMAGES_FOR_TEST[selected_image]\n","image_np = load_image_into_numpy_array(image_path)\n","\n","# Flip horizontally\n","if(flip_image_horizontally):\n","  image_np[0] = np.fliplr(image_np[0]).copy()\n","\n","# Convert image to grayscale\n","if(convert_image_to_grayscale):\n","  image_np[0] = np.tile(\n","    np.mean(image_np[0], 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n","\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np[0])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"FTHsFjR6HNwb"},"source":["## Doing the inference\n","\n","To do the inference we just need to call our TF Hub loaded model.\n","\n","Things you can try:\n","* Print out `result['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).\n","* inspect other output keys present in the result. A full documentation can be seen on the models documentation page (pointing your browser to the model handle printed earlier)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27089,"status":"ok","timestamp":1682745717906,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"},"user_tz":-330},"id":"Gb_siXKcnnGC","outputId":"a85b082b-84c2-4016-eab1-380286a84a4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['box_classifier_features', 'rpn_box_encodings', 'raw_detection_boxes', 'rpn_objectness_predictions_with_background', 'proposal_boxes', 'detection_classes', 'detection_anchor_indices', 'num_proposals', 'rpn_box_predictor_features', 'detection_scores', 'image_shape', 'mask_predictions', 'proposal_boxes_normalized', 'class_predictions_with_background', 'raw_detection_scores', 'detection_boxes', 'final_anchors', 'anchors', 'detection_multiclass_scores', 'rpn_features_to_crop', 'detection_masks', 'refined_box_encodings', 'num_detections'])\n"]}],"source":["# running inference\n","results = hub_model(image_np)\n","\n","# different object detection models have additional results\n","# all of them are explained in the documentation\n","result = {key:value.numpy() for key,value in results.items()}\n","print(result.keys())"]},{"cell_type":"code","source":["# result['detection_boxes']\n","result['detection_masks'][0][0][1]\n","# result['detection_classes']\n","# result['detection_scores']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkxQH6fPyUbA","executionInfo":{"status":"ok","timestamp":1682745965960,"user_tz":-330,"elapsed":477,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}},"outputId":"829ac345-f2e3-42e8-8bea-5207a52cc90c"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.50002816e-05, 4.66723941e-05, 7.29445019e-05, 2.01732633e-04,\n","       6.61083846e-04, 3.08374059e-03, 1.14944875e-02, 3.71472463e-02,\n","       1.05353117e-01, 2.78143466e-01, 5.62060475e-01, 7.98465073e-01,\n","       9.07232642e-01, 9.33565438e-01, 9.30402756e-01, 9.06378448e-01,\n","       8.51081967e-01, 7.51890063e-01, 6.28219187e-01, 5.03602087e-01,\n","       3.94830853e-01, 2.86993146e-01, 1.94655851e-01, 1.01403177e-01,\n","       3.89537066e-02, 1.49473175e-02, 6.09844038e-03, 2.41386378e-03,\n","       9.43310093e-04, 3.58097139e-04, 1.25817460e-04, 4.94842388e-05,\n","       2.44929743e-05], dtype=float32)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"IZ5VYaBoeeFM"},"source":["## Visualizing the results\n","\n","Here is where we will need the TensorFlow Object Detection API to show the squares from the inference step (and the keypoints when available).\n","\n","the full documentation of this method can be seen [here](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py)\n","\n","Here you can, for example, set `min_score_thresh` to other values (between 0 and 1) to allow more detections in or to filter out more detections."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717,"output_embedded_package_id":"1nIjDRtf78R4WCyDhKNYLnvj5WG640Qbq"},"executionInfo":{"elapsed":13119,"status":"ok","timestamp":1682746022303,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"},"user_tz":-330},"id":"2O7rV8g9s8Bz","outputId":"d8d54992-fa69-40dd-c4e3-5db5aab228fe"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["label_id_offset = 0\n","image_np_with_detections = image_np.copy()\n","\n","# Use keypoints if available in detections\n","keypoints, keypoint_scores = None, None\n","if 'detection_keypoints' in result:\n","  keypoints = result['detection_keypoints'][0]\n","  keypoint_scores = result['detection_keypoint_scores'][0]\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_detections[0],\n","      result['detection_boxes'][0],\n","      (result['detection_classes'][0] + label_id_offset).astype(int),\n","      result['detection_scores'][0],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=.40,\n","      agnostic_mode=False)\n","      # keypoints=keypoints,\n","      # keypoint_scores=keypoint_scores,\n","      # keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n","\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np_with_detections[0])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Qaw6Xi08NpEP"},"source":["## [Optional]\n","\n","Among the available object detection models there's Mask R-CNN and the output of this model allows instance segmentation.\n","\n","To visualize it we will use the same method we did before but adding an aditional parameter: `instance_masks=output_dict.get('detection_masks_reframed', None)`\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717,"output_embedded_package_id":"1F3YCMwA00kFDAm0VyMjENybyTeHtpm5v"},"executionInfo":{"elapsed":17143,"status":"ok","timestamp":1682746137253,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"},"user_tz":-330},"id":"zl3qdtR1OvM_","outputId":"e4ad6f1a-1f8f-4259-b198-3c5a2abde267"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Handle models with masks:\n","image_np_with_mask = image_np.copy()\n","\n","if 'detection_masks' in result:\n","  # we need to convert np.arrays to tensors\n","  detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n","  detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n","\n","  # Reframe the bbox mask to the image size.\n","  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","            detection_masks, detection_boxes,\n","              image_np.shape[1], image_np.shape[2])\n","  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n","                                      tf.uint8)\n","  result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_mask[0],\n","      result['detection_boxes'][0],\n","      (result['detection_classes'][0] + label_id_offset).astype(int),\n","      result['detection_scores'][0],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=.30,\n","      agnostic_mode=False,\n","      instance_masks=result.get('detection_masks_reframed', None),\n","      line_thickness=2)\n","\n","plt.figure(figsize=(24,32))\n","plt.imshow(image_np_with_mask[0])\n","plt.show()"]},{"cell_type":"code","source":["len(result['detection_masks_reframed'][0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLY7oV_b0sPl","executionInfo":{"status":"ok","timestamp":1679245406216,"user_tz":-330,"elapsed":613,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}},"outputId":"78bbbb5c-b542-4ece-9551-b48fb068cd40"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1352"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["len(result['detection_masks_reframed'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IlrLNhbL1qOk","executionInfo":{"status":"ok","timestamp":1679245633277,"user_tz":-330,"elapsed":243,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}},"outputId":"5a45649a-fc6b-44ca-df18-47679fbdd9ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["print(result['detection_masks_reframed'][0][0][1200:1351])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sm-pBrxi1FxC","executionInfo":{"status":"ok","timestamp":1679245569466,"user_tz":-330,"elapsed":310,"user":{"displayName":"Mayank Parikh","userId":"11709082426090810996"}},"outputId":"18998d10-d34f-4c1b-e7ac-817eed12577e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0]\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb","timestamp":1679188218185}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}